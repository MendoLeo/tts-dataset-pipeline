# ğŸ§ TTS & ASR Dataset Pipeline


An open-source pipeline designed to simplify the creation of datasets for Text-to-Speech (TTS) and Automatic Speech Recognition (ASR), supporting both specific (biblical) and generic (any corpus/language) use cases.

---

## ğŸ“Œ Table of Contents

1. [ğŸ¯ Motivation & Inspirations](#-motivation--inspirations)  
2. [ğŸ§  Pipeline Architecture](#-pipeline-architecture)  
3. [ğŸ“š Use Cases](#-use-cases)  
4. [âš™ï¸ Installation](#-installation)  
5. [ğŸ§¾ Data Preparation](#-data-preparation)  
6. [âš™ï¸ Common Preprocessing Steps](#-common-preprocessing-steps)  
7. [ğŸ“– Biblical Case](#-biblical-case)  
8. [ğŸŒ Generic Case](#-generic-case)  
9. [ğŸ™Œ Contributing](#-contributing)  
10. [ğŸ“„ License](#-license)

---

## ğŸ¯ Motivation & Inspirations


This project was born out of a desire to expand access to speech technologies for all languages, especially **low-resource languages**.  
Inspired by Meta AIâ€™s **Massively Multilingual Speech (MMS)** project, this open-source pipeline aims to make TTS/ASR dataset creation easier by providing a full set of tools for:

- preprocessing text and audio data,
- automatic alignment,
- data filtering and formatting.

---

## ğŸ§  Pipeline Architecture

```
Raw Data (audio/text)
      â”‚
      â–¼
Preprocessing (conversion + cleaning)
      â”‚
      â–¼
Text-audio alignment
      â”‚
      â–¼
Alignment filtering
      â”‚
      â–¼
Final formatting (CSV, JSON, etc.)
```

---

## ğŸ“š Use Cases

This pipeline supports **two main scenarios**:

- ğŸ“– **Biblical case**: Texts from scriptures or other books, often structured using book,chapter,verse segmentation.
- ğŸŒ **Generic case**: Any data with transcription and audio (podcasts, stories, interviews, etc.).

---

## âš™ï¸ Installation

```bash
# 1. Clone the repository
git clone https://github.com/MendoLeo/tts-dataset-pipeline.git
cd tts-dataset-pipeline

# 2. Install Python dependencies
pip install -r requirements.txt
```

### ğŸ“Œ C++ Alignment Dependency (Generic case only)

```bash
cd forced-alignhf-model
pip install pybind11
python setup.py build_ext --inplace
```

> âš ï¸ Requirements: Python 3.10, `pybind11`, and a C++ compiler (`g++` recommended)

---

## ğŸ§¾ Data Preparation

### ğŸ“– Biblical Data

This case is inspired by [OpenBible](https://github.com/bookbot-hive/OpenBible-TTShttps://github.com/bookbot-hive/OpenBible-TTS) work

- Required format: structure transcripts on `.json` file format:
  ```json
  [
      {
          "numVerset": "MAT.1.1",
          "verset": "Kalate Ã©ndane YÃ©sus Krist, e mona David, e mon Abraham."
      },
      {
          "numVerset": "MAT.1.2",
          "verset": "Abraham a nga biaÃ© Izak, Izak a nga biaÃ© Yakob, Yakob a nga biaÃ© Yuda baa be bobenyaÃ±. "
      },
      {
          "numVerset": "MAT.1.3",
          "verset": "Yuda a nga biaÃ© FarÃ©s a Zara aluÊ¼u baa Tamar. FarÃ©s a nga biaÃ© EsrÃ´m, EsrÃ´m a nga biaÃ© Aram. "
      },
      {
          "numVerset": "MAT.1.4",
          "verset": "Aram a nga biaÃ© Aminadab, Aminadab ke a biaÃ© NaasÃ´n. NaasÃ´n ke a biaÃ© SalmÃ´n. "
      },
  ]
  ```
  Examples of these JSON files can be found in the [Drive](https://drive.google.com/drive/folders/1mq9C3AQU0J5xAwwUfWQDwoTnbH6OYi3G) as for more than 26 cameroonian dialects Bible transcripts (good starter to build your own dataset, check if your dialect is [available](https://docs.google.com/spreadsheets/d/1m2badLeGIzfrhetIE0BpXamtGAWBhvEP/edit?usp=drive_web&ouid=107335318586372564034&rtpof=true).


- Structure:
  ```
  â”œâ”€â”€ audio_dir/
    â”œâ”€â”€ MAT
      â”œâ”€â”€ MAT_001.wav
      â”œâ”€â”€ MAT_002.wav
      â”œâ”€â”€ MAT_003.wav
    â”œâ”€â”€ 1CO
    ...
  â”œâ”€â”€ transcripts/
    â”œâ”€â”€ MAT.json
    â”œâ”€â”€ PSA.json
    â”œâ”€â”€ GEN.json
    â”œâ”€â”€ REV.json
    ...
    ```

### ğŸŒ Generic Data

- Required format: free-form transcription `.txt`
- Structure:
  ```
  â”œâ”€â”€ text_dir/
    â”œâ”€â”€ AV1.txt
    â”œâ”€â”€ AV2.txt

  â”œâ”€â”€ audio_dir/
    â”œâ”€â”€ AV1.wav
    â”œâ”€â”€ AV2.wav
  ```
  ---

AV1.txt must contain text to align with audio as:

  ```
  ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ê³µì›ì— ê°€ê¸°ë¡œ í–ˆë‹¤.
  ìš°ë¦¬ëŠ” ìì „ê±°ë¥¼ íƒ€ê³ , ê¸¸ì„ ë”°ë¼ ì²œì²œíˆ ë‹¬ë ¸ë‹¤
  ê³µì›ì— ë„ì°©í•˜ë‹ˆ ì‚¬ëŒë“¤ì´ ë§ì´ ìˆì—ˆë‹¤.
  ì•„ì´ë“¤ì´ ë†€ì´í„°ì—ì„œ ë†€ê³ , ì–´ë¥¸ë“¤ì€ ì‚°ì±…ì„ í•˜ê³  ìˆì—ˆë‹¤

  ```

## âš™ï¸ Common Preprocessing Steps

```bash
 cd data_prep
```

### ğŸ”„ Audio Conversion

Convert audio files to:
- `wav` 16kHz
- `wav` 22kHz
- `wav` 44kHz

  ```bash
    python convert_audio.py \
      --audio_dir ./audio_files \
      --sample 16000 \ 
      --output_dir wav_output

  ```

### ğŸ”‡ Audio Denoising

Automatically removes background noise or unwanted music.

  ```bash
    python denoising.py \ 
      --src_path /noised/audios \ 
      --output_dir /denoised/audios
  ```

---

## ğŸ“– Biblical Case

### ğŸ“Œ Alignment

- **Align single book:**
  ```bash
    python run_segmentation.py \
      --json_path /transcripts/json-file/PSA.json \
      --audio_dir /audio_dir/PSA \
      --output_dir /outputs/PSA \
      --language 'bum' \
      --chunk_size_s 15
    ```

which will generate:

```
outputs/PSA/
â”œâ”€â”€ PSA_001
â”‚   â”œâ”€â”€ PSA_001_001.txt
â”‚   â”œâ”€â”€ PSA_001_001.wav
â”‚   â”œâ”€â”€ PSA_001_002.txt
â”‚   â”œâ”€â”€ PSA_001_002.wav
â”‚   â”œâ”€â”€ ...
â”œâ”€â”€ PSA_002
â”‚   â”œâ”€â”€ PSA_002_001.txt
â”‚   â”œâ”€â”€ PSA_002_001.wav
â”‚   â”œâ”€â”€ PSA_002_002.txt
â”‚   â”œâ”€â”€ PSA_002_002.wav
â”œâ”€â”€ ...
...
```
- **Align multiple books:**
  ```bash
    cd scripts-bash
    segmentation.sh -j /to/json_files -a /to/audio_files -o /to/output_dir -b "GEN EXO PSA" -c 15

  ```

### ğŸ§¹ Filtering

#### Arguments

| Argument | Description | Default |
|---|---|---|
| `--audio_path` | Path to the audio and transcript file with the same name | Required |
| `--language` | Language in ISO 639-3 code | Required |
| `--chunck_size` | Chunk size in seconds | 15 seconds as in mms |
| `--probability_difference_threshold` | threshold for bad alignment removing | -0.2 as in mms project |

- **Filter single book:**
  ```bash
    python run_filter.py \
    --audio_dir /aligned/GEN/ \
    --output_dir /output/filtered \
    --language 'bum' \
    --chunk_size_s 15 \
    --probability_difference_threshold -0.2
  ```
- **Filter multiple books:**

  ```bash
    cd scripts-bash
    run_filter.sh -a /path/to/audio_files -o /path/to/output_dir -b "GEN EXO PSA" -t -0.3

  ```

---

## ğŸŒ Generic Case

### ğŸ”§ Alignment Setup

This case uses a CTC model implemented in C++ by [Mohamoud Ashraf](https://github.com/MahmoudAshraf97/ctc-forced-aligner/tree/main) with integration via `pybind11`.

### ğŸ” Alignment

#### Arguments


| Argument | Description | Default |
|---|---|---|
| `--audio_path` | Path to the audio file | Required |
| `--text_path` | Path to the text file | Required |
| `--language` | Language in ISO 639-3 code | Required |
| `--romanize` | Enable romanization for non-latin scripts or for multilingual models regardless of the language, required when using the default model| False |
| `--split_size` | Alignment granularity: "sentence", "word", or "char" | "word" |
| `--star_frequency` | Frequency of `<star>` token: "segment" or "edges" | "edges" |
| `--merge_threshold` | Merge threshold for segment merging | 0.00 |
| `--alignment_model` | Name of the alignment model | [MahmoudAshraf/mms-300m-1130-forced-aligner](https://huggingface.co/MahmoudAshraf/mms-300m-1130-forced-aligner) |
| `--compute_dtype` | Compute dtype for inference | "float32" |
| `--batch_size` | Batch size for inference | 4 |
| `--window_size` | Window size in seconds for audio chunking | 30 |
| `--context_size` | Overlap between chunks in seconds | 2 |
| `--attn_implementation` | Attention implementation | "eager" |
| `--device` | Device to use for inference: "cuda" or "cpu" | "cuda" if available, else "cpu" |
| `--generate_txt` | Define if you want text file with timestamp and text alignment |False|
| `--generate_json` | Define if you want text with timestamp and alignment score|False|






```bash
  cd forced-alignhf-model/ctc_forced_aligner

  python align_batch.py \
      --audio_dir "/content/tts-dataset-pipeline/data/audios" \
      --text_dir "/content/tts-dataset-pipeline/data/transcripts" \
      --output_dir "/content/sample_data/pipeline-align" \
      --language "bum" \
      --romanize \
      --segment_audio \
      --generate_txt \
      --split_size "sentence"
```

- **Optional:** Bash script alignment (serial or parallel)

```bash
   align_batch_launcher.sh \
      --audio_dir "/content/tts-dataset-pipeline/data/audios" \
      --text_dir "/content/tts-dataset-pipeline/data/transcripts" \
      --output_dir "/content/sample_data/pipeline" \
      --language "bum" \
      --romanize \
      --segment_audio \
      --generate_txt \
      --split_size "sentence"
```

### ğŸ§¹ Generic Filtering

```bash
    cd data_prep
    python generic_filter.py \
      --audio_dir /path/to/align/data \
      --output_dir /path/to/cleaned/alignment \
      --language "bum" \
      --probability_difference_threshold -0.25 \
  ```

---

## ğŸ™Œ Contributing

You can:

- Report a bug or suggest a feature
- Submit a PR with local language use cases
- Add a new language (locale, test sets, etc.)
- Translate this README into your language

---

## ğŸ“„ License

This project incorporates components and resources licensed under different open-source and open-content licenses:

- ğŸ§© Parts of the **code** are licensed under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).
- ğŸ§± Some elements are licensed under the [BSD 3-Clause License](https://opensource.org/licenses/BSD-3-Clause).
- ğŸ“š Some models are under the [Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)](https://creativecommons.org/licenses/by-nc/4.0/).

Unless otherwise specified in individual files, this repository as a whole is distributed under the: **(CC BY-NC 4.0)** license.


---

## ğŸ‘ Acknowledgement

This project would not be possible without the contributions and inspirations from the open-source community and the research teams behind:

- [Massively Multilingual Speech (MMS)](https://github.com/facebookresearch/fairseq/tree/main/examples/mms) by Meta AI
- [Tikeng Notsawo Pascal et al](https://openreview.net/forum?id=Q5ZxoD2LqcI) for their work on building first bible transcript dataset for cameroonian dialects
- [Mohamoud Ashraf](https://github.com/MahmoudAshraf97/ctc-forced-aligner/tree/main) for open sourced his work, where we use timestamp alignemnt to have complet alignment with audio-text generation
- [OpenBible](https://github.com/bookbot-hive/OpenBible-TTShttps://github.com/bookbot-hive/OpenBible-TTS) for open sourced alignment method for bible case that we ameliore text processing to expand to all language also adding denoising and audio conversion
- All contributors who support local language tech
- Users and testers helping improve the pipeline continuously

Thank you for your support and collaboration!

